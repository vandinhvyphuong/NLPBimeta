{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "pretrain_bert_S.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.13 64-bit ('bimeta': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f181f9a8cefa4bb0a8c32550623610c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c09e64345e584668b54dfd5989280a2f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39d8822ddb004479b5bac692910604f8",
              "IPY_MODEL_1f94b048b10a4e39ac8f51591bd2f920",
              "IPY_MODEL_9c05fcadfd0542bbb6b51de3713a0429"
            ]
          }
        },
        "c09e64345e584668b54dfd5989280a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39d8822ddb004479b5bac692910604f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_864c0f58b7b44e1ea5648f5419b3781e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0e225b86f6482e856625249399b4bf"
          }
        },
        "1f94b048b10a4e39ac8f51591bd2f920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3352a7a726b54d7faa6a42c93f7e0bef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a8d8b6b7f76453ba615a97ffa3c5417"
          }
        },
        "9c05fcadfd0542bbb6b51de3713a0429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07bc623debad4b5e94b0134fbb1c00c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [02:13&lt;00:00, 71.67s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3acc9c3f5e764cf4b3488bd588a589de"
          }
        },
        "864c0f58b7b44e1ea5648f5419b3781e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0e225b86f6482e856625249399b4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3352a7a726b54d7faa6a42c93f7e0bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a8d8b6b7f76453ba615a97ffa3c5417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07bc623debad4b5e94b0134fbb1c00c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3acc9c3f5e764cf4b3488bd588a589de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "interpreter": {
      "hash": "5cef0a9f8ded764309eccbc26778b077c5ace5f1e81d93105e2fc9ddc071b567"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "import glob, os, time, sys\n",
        "import json\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import argparse\n",
        "\n",
        "from dataset.genome import GenomeDataset\n",
        "from dataset.utils import load_meta_reads, build_bert_corpus_v2\n",
        "import utils.utils as utils\n",
        "from debug.visualize import get_group_label, visualize\n",
        "from utils.metrics import genome_acc, group_precision_recall\n",
        "\n",
        "import torch\n",
        "from bert_pytorch.dataset import BERTDataset, WordVocab\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import tqdm"
      ],
      "outputs": [],
      "metadata": {
        "id": "26_rXFFKaO1Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from torch.utils.data import Dataset\n",
        "import tqdm\n",
        "import torch\n",
        "import random\n",
        "\n",
        "\n",
        "class BERTDataset_ForInference(Dataset):\n",
        "    def __init__(self, corpus_path, vocab, seq_len, encoding=\"utf-8\", corpus_lines=None, on_memory=True):\n",
        "        self.vocab = vocab\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "        self.on_memory = on_memory\n",
        "        self.corpus_lines = corpus_lines\n",
        "        self.corpus_path = corpus_path\n",
        "        self.encoding = encoding\n",
        "\n",
        "        with open(corpus_path, \"r\", encoding=encoding) as f:\n",
        "            if self.corpus_lines is None and not on_memory:\n",
        "                for _ in tqdm.tqdm(f, desc=\"Loading Dataset\", total=corpus_lines):\n",
        "                    self.corpus_lines += 1\n",
        "\n",
        "            if on_memory:\n",
        "                self.lines = [line[:-1].split(\"\\t\")\n",
        "                              for line in tqdm.tqdm(f, desc=\"Loading Dataset\", total=corpus_lines)]\n",
        "                self.corpus_lines = len(self.lines)\n",
        "\n",
        "        if not on_memory:\n",
        "            self.file = open(corpus_path, \"r\", encoding=encoding)\n",
        "            self.random_file = open(corpus_path, \"r\", encoding=encoding)\n",
        "\n",
        "            for _ in range(random.randint(self.corpus_lines if self.corpus_lines < 1000 else 1000)):\n",
        "                self.random_file.__next__()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.corpus_lines\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        t1, t2 = self.get_corpus_line(item)\n",
        "        is_next_label = 1\n",
        "        # t1, t2, is_next_label = self.random_sent(item)\n",
        "        # t1_random, t1_label = self.random_word(t1)\n",
        "        # t2_random, t2_label = self.random_word(t2)\n",
        "\n",
        "        t1_random, t1_label = self.token2token_id(t1)\n",
        "        t2_random, t2_label = self.token2token_id(t2)\n",
        "\n",
        "        # [CLS] tag = SOS tag, [SEP] tag = EOS tag\n",
        "        t1 = [self.vocab.sos_index] + t1_random + [self.vocab.eos_index]\n",
        "        t2 = t2_random + [self.vocab.eos_index]\n",
        "\n",
        "        t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index]\n",
        "        t2_label = t2_label + [self.vocab.pad_index]\n",
        "\n",
        "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
        "        bert_input = (t1 + t2)[:self.seq_len]\n",
        "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
        "\n",
        "        padding = [self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))]\n",
        "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
        "\n",
        "        output = {\"bert_input\": bert_input,\n",
        "                  \"bert_label\": bert_label,\n",
        "                  \"segment_label\": segment_label,\n",
        "                  \"is_next\": is_next_label}\n",
        "\n",
        "        return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "    def token2token_id(self, sentence):\n",
        "        tokens = sentence.split()\n",
        "        output_label = []\n",
        "\n",
        "        for i, token in enumerate(tokens):\n",
        "            tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n",
        "            output_label.append(0)\n",
        "\n",
        "        return tokens, output_label\n",
        "\n",
        "    def get_corpus_line(self, item):\n",
        "        if self.on_memory:\n",
        "            return self.lines[item][0], self.lines[item][1]\n",
        "        else:\n",
        "            line = self.file.__next__()\n",
        "            if line is None:\n",
        "                self.file.close()\n",
        "                self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n",
        "                line = self.file.__next__()\n",
        "\n",
        "            t1, t2 = line[:-1].split(\"\\t\")\n",
        "            return t1, t2"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "sys.path.append('.')\n",
        "\n",
        "DATASET_DIR = '../../Data/test/input/'\n",
        "# Specifc dataset or all of them\n",
        "DATASET_NAME = ['S1_test', 'hmp_test']\n",
        "# DATASET_NAME = 'all'\n",
        "BIMETAOUT_DIR = '../../Data/test/output/bimetaout/'\n",
        "RESULT_DIR = '../../Data/test/output/bertbimetaout/'"
      ],
      "outputs": [],
      "metadata": {
        "id": "y8R7FY03aWtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Hyperparameters\n",
        "KMERS = [4]\n",
        "# Training batchsize\n",
        "BATCH_SIZE = 256\n",
        "# Number of epochs for pretraining\n",
        "PRETRAIN_EPOCHS = 2000\n",
        "# Dir contains raw fasta data\n",
        "is_save_each_corpus = True"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y1WlS1ydaYmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import random\n",
        "def build_bert_corpus(reads, k_mer_length=4):\n",
        "    '''\n",
        "    Output will be a text file, where:\n",
        "    - each line is a read which is represented by 2 sentence of k-mer,\n",
        "        each k-mer is separated from the others with space\n",
        "    '''\n",
        "    corpus = []\n",
        "    for read in reads:\n",
        "        lines = []\n",
        "        n = len(read)\n",
        "        m = n // 2\n",
        "\n",
        "        kmers_first_sentence = []\n",
        "        for j in range(0, m - k_mer_length + 1):\n",
        "            k_mer = read[j:(j + k_mer_length)]\n",
        "            kmers_first_sentence.append(k_mer)\n",
        "        \n",
        "        kmers_second_sentence = []\n",
        "        for j in range(m, n - k_mer_length + 1):\n",
        "            k_mer = read[j:(j + k_mer_length)]\n",
        "            kmers_second_sentence.append(k_mer)\n",
        "        \n",
        "        first_sentence = ' '.join(kmers_first_sentence)\n",
        "        second_sentence = ' '.join(kmers_second_sentence)\n",
        "        document = first_sentence + '\\t' + second_sentence + '\\n'\n",
        "        \n",
        "        corpus.append(document)\n",
        "\n",
        "    return corpus"
      ],
      "outputs": [],
      "metadata": {
        "id": "JB_x-byDcxWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def build_bert_corpus_v2(reads, k_mer_length=4):\n",
        "    corpus = []\n",
        "    for read in reads:\n",
        "        kmers_per_read = []\n",
        "        for j in range(0,len(read)-k_mer_length + 1):\n",
        "            k_mer = read[j:j+k_mer_length]\n",
        "            kmers_per_read.append(k_mer)\n",
        "        \n",
        "        middle_idx = len(kmers_per_read) // 2\n",
        "        # line = ' '.join(kmers_per_read)\n",
        "        sentence = ' '.join(kmers_per_read[:middle_idx]) + ' \\t ' + ' '.join(kmers_per_read[middle_idx:]) + '\\n'\n",
        "        \n",
        "        corpus.append(sentence)\n",
        "\n",
        "    return corpus"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "if DATASET_NAME == 'all':\n",
        "    raw_datasets = glob.glob(DATASET_DIR + '/*.fna')\n",
        "else:\n",
        "    if type(DATASET_NAME) == list:\n",
        "        raw_datasets = [os.path.join(DATASET_DIR, ds_name + '.fna') for ds_name in DATASET_NAME]\n",
        "    else:    \n",
        "        raw_datasets = [os.path.join(DATASET_DIR, DATASET_NAME + '.fna')]\n",
        "    #raw_datasets = [os.path.join(DATASET_DIR, DATASET_NAME + '.fna')]\n",
        "\n",
        "# Mapping of dataset and its corresponding number of clusters\n",
        "with open('config/dataset_metadata.json', 'r') as f:\n",
        "    n_clusters_mapping = json.load(f)['datasets']\n",
        "\n",
        "raw_datasets.sort()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "raw_datasets"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['../../Data/test/input/S1_test.fna', '../../Data/test/input/hmp_test.fna']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "dataset = raw_datasets[0]\n",
        "dataset_name = os.path.basename(dataset).split('.fna')[0]\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "print('Processing dataset: ', dataset_name)\n",
        "\n",
        "bimetaout_file = os.path.join(BIMETAOUT_DIR, dataset_name + '.json')\n",
        "\n",
        "log_file = os.path.join(RESULT_DIR, dataset_name + '.log.txt')\n",
        "log = open(log_file, \"w\")\n",
        "log.write('------------------------------------------------------- ')\n",
        "log.write('\\nProcessing dataset ' + dataset_name)\n",
        "\n",
        "n_clusters = n_clusters_mapping[dataset_name]\n",
        "\n",
        "print('Prior number of clusters: ', n_clusters)\n",
        "log.write('\\nPrior number of clusters: ' + str(n_clusters))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------\n",
            "Processing dataset:  S1_test\n",
            "Prior number of clusters:  2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "t0 = time.time()\n",
        "# Load group file (phase 1 of bimeta) according to dataset_name\n",
        "print('Loading groups/seeds: ...')\n",
        "groups, seeds = utils.load_groups_seeds(BIMETAOUT_DIR, dataset_name)\n",
        "print('Total number of groups: ', len(groups))\n",
        "log.write('\\nTotal number of groups/seeds: ' + str(len(groups)))\n",
        "print('Time to load groups: ', (time.time() - t0))\n",
        "log.write('\\nTime to load groups: ' + str((time.time() - t0)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading groups/seeds: ...\n",
            "Total number of groups:  396\n",
            "Time to load groups:  0.0046346187591552734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# Read fasta dataset\n",
        "t1 = time.time()\n",
        "print('Loading reads ...')\n",
        "reads, labels = load_meta_reads(dataset, type='fasta')\n",
        "print('Total number of reads: ', len(labels))\n",
        "log.write('\\nTotal number of reads: ' + str(len(labels)))\n",
        "print('Time to load reads: ', (time.time() - t1))\n",
        "log.write('\\nTime to load reads: ' + str((time.time() - t1)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading reads ...\n",
            "Total number of reads:  400\n",
            "Time to load reads:  0.03836774826049805\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "t2 = time.time()\n",
        "# Creating bert corpus...\n",
        "corpus = build_bert_corpus_v2(reads, k_mer_length=4)\n",
        "print('Time to create corpus from reads: ', (time.time() - t2))\n",
        "log.write('\\nTime to create corpus from reads: ' + str((time.time() - t2)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to create corpus from reads:  0.02024102210998535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "t3 = time.time()\n",
        "print('Save corpus for current dataset ...')\n",
        "# Save corpus for current dataset\n",
        "bert_corpus_file = os.path.join(RESULT_DIR, dataset_name + '.bert_corpus.txt')\n",
        "if is_save_each_corpus:\n",
        "    with open(bert_corpus_file, 'w') as f:\n",
        "        f.writelines(corpus)\n",
        "        print('Saved bert corpus to ', bert_corpus_file)\n",
        "print('Time to save corpus for current dataset: ', (time.time() - t3))\n",
        "log.write('\\nTime to save corpus for current dataset: ' + str((time.time() - t3)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save corpus for current dataset ...\n",
            "Saved bert corpus to  ../../Data/test/output/bertbimetaout/S1_test.bert_corpus.txt\n",
            "Time to save corpus for current dataset:  0.0028955936431884766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "sys.path.append('.')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/home/hoangqd/Projects/nlp-bimeta-binning'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!bert-vocab -c '/home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert_corpus.txt' -o '/home/hoangqd/Data/test/output/bertbimetaout/vocab'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Vocab\n",
            "400it [00:00, 12586.15it/s]\n",
            "VOCAB SIZE: 656\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!cat '/home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert_corpus.txt' | head -10"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATAA TAAT AATT ATTG TTGG TGGC GGCA GCAA CAAG AAGT AGTG GTGT TGTT GTTT TTTT TTTA TTAG TAGT AGTC GTCT TCTT CTTA TTAG TAGA AGAG GAGA AGAG GAGA AGAT GATT ATTC TTCT TCTC CTCT TCTA CTAA TAAG AAGT AGTC GTCT TCTA CTAA TAAC AACT ACTT CTTG TTGA TGAA GAAC AACT ACTC CTCA TCAA CAAT AATT ATTT TTTG TTGG TGGA GGAA GAAT AATC ATCA TCAT CATT ATTT TTTC TTCC TCCC CCCA CCAA CAAT AATT ATTT TTTT TTTT TTTA\tTTTC TTCA TCAA CAAA AAAC AACA ACAC CACT ACTT CTTT TTTA TTAC TACA ACAC CACC ACCT CCTC CTCT TCTA CTAC TACC ACCA CCAT CATT ATTC TTCA TCAT CATT ATTC TTCA TCAA CAAT AATT ATTG TTGG TGGA GGAT GATC ATCA TCAC CACA ACAA CAAA AAAT AATA ATAC TACA ACAG CAGA AGAG GAGC AGCA GCAG CAGT AGTG GTGT TGTA GTAT TATT ATTT TTTG TTGA TGAG GAGA AGAT GATA ATAT TATC ATCC TCCT CCTG CTGA TGAA GAAA AAAG AAGA AGAT\n",
            "TAAT AATT ATTA TTAG TAGT AGTT GTTA TTAG TAGG AGGT GGTA GTAA TAAA AAAG AAGG AGGA GGAA GAAC AACC ACCT CCTT CTTG TTGT TGTT GTTA TTAA TAAT AATA ATAA TAAG AAGA AGAC GACT ACTA CTAG TAGG AGGT GGTT GTTT TTTT TTTA TTAT TATT ATTA TTAA TAAC AACA ACAC CACA ACAA CAAA AAAT AATA ATAA TAAA AAAG AAGG AGGG GGGG GGGT GGTT GTTC TTCA TCAA CAAA AAAA AAAG AAGA AGAA GAAA AAAC AACC ACCC CCCC CCCT CCTT CTTT\tGTTT TTTC TTCA TCAA CAAA AAAA AAAA AAAC AACA ACAT CATG ATGT TGTT GTTG TTGA TGAA GAAA AAAA AAAA AAAT AATA ATAA TAAA AAAC AACA ACAA CAAA AAAA AAAA AAAC AACA ACAG CAGT AGTA GTAC TACT ACTC CTCC TCCA CCAG CAGA AGAA GAAA AAAA AAAA AAAT AATA ATAG TAGT AGTT GTTA TTAC TACC ACCT CCTC CTCA TCAT CATA ATAA TAAT AATC ATCT TCTA CTAA TAAA AAAA AAAG AAGC AGCT GCTA CTAG TAGG AGGG GGGT GGTA GTAG TAGC\n",
            "TATC ATCT TCTA CTAA TAAT AATT ATTC TTCC TCCC CCCC CCCT CCTC CTCA TCAC CACT ACTT CTTA TTAT TATT ATTC TTCT TCTC CTCA TCAC CACT ACTC CTCA TCAA CAAC AACT ACTT CTTG TTGT TGTA GTAT TATT ATTC TTCA TCAT CATC ATCT TCTT CTTG TTGG TGGT GGTT GTTA TTAG TAGC AGCT GCTT CTTT TTTT TTTA TTAT TATG ATGT TGTA GTAG TAGG AGGA GGAA GAAA AAAG AAGA AGAG GAGC AGCA GCAA CAAC AACG ACGC CGCT GCTC CTCG TCGC CGCT\tACTC CTCT TCTT CTTT TTTA TTAT TATC ATCA TCAA CAAT AATT ATTG TTGA TGAA GAAC AACT ACTT CTTA TTAA TAAG AAGG AGGG GGGA GGAA GAAT AATT ATTC TTCA TCAA CAAA AAAG AAGA AGAG GAGT AGTT GTTA TTAA TAAG AAGA AGAT GATA ATAT TATT ATTT TTTA TTAA TAAG AAGG AGGC GGCT GCTA CTAA TAAG AAGC AGCT GCTT CTTC TTCA TCAG CAGA AGAC GACA ACAT CATT ATTC TTCC TCCC CCCT CCTA CTAA TAAA AAAC AACA ACAT CATG ATGA TGAA\n",
            "TCTA CTAG TAGA AGAT GATG ATGG TGGA GGAA GAAC AACT ACTA CTAA TAAG AAGA AGAT GATA ATAG TAGT AGTA GTAG TAGT AGTT GTTC TTCT TCTA CTAA TAAA AAAT AATA ATAC TACT ACTT CTTC TTCA TCAA CAAC AACA ACAA CAAT AATA ATAG TAGT AGTA GTAG TAGA AGAT GATA ATAG TAGA AGAG GAGA AGAG GAGA AGAT GATC ATCA TCAT CATA ATAC TACT ACTT CTTA TTAT TATG ATGT TGTA GTAT TATG ATGA TGAT GATC ATCC TCCT CCTG CTGA TGAG GAGT\tCTAA TAAA AAAC AACA ACAT CATA ATAG TAGA AGAG GAGA AGAA GAAG AAGA AGAA GAAG AAGT AGTA GTAG TAGA AGAT GATT ATTA TTAC TACT ACTG CTGC TGCT GCTA CTAG TAGG AGGA GGAG GAGT AGTC GTCC TCCA CCAA CAAA AAAG AAGA AGAC GACT ACTC CTCC TCCT CCTG CTGT TGTC GTCA TCAT CATT ATTA TTAA TAAT AATC ATCC TCCA CCAT CATT ATTA TTAC TACT ACTC CTCA TCAA CAAT AATA ATAC TACT ACTA CTAG TAGA AGAG GAGG AGGA GGAA GAAG\n",
            "ATCC TCCG CCGA CGAC GACA ACAG CAGT AGTG GTGG TGGA GGAT GATC ATCC TCCA CCAA CAAT AATT ATTA TTAC TACA ACAA CAAA AAAA AAAA AAAC AACA ACAC CACC ACCT CCTA CTAA TAAA AAAA AAAG AAGG AGGG GGGC GGCT GCTT CTTT TTTA TTAA TAAC AACT ACTC CTCA TCAG CAGA AGAT GATA ATAG TAGC AGCC GCCA CCAA CAAT AATT ATTT TTTT TTTT TTTA TTAA TAAT AATT ATTT TTTT TTTT TTTT TTTA TTAA TAAA AAAG AAGA AGAG GAGG AGGG GGGA\tGAGA AGAA GAAT AATG ATGA TGAT GATG ATGG TGGA GGAG GAGA AGAT GATA ATAT TATG ATGG TGGT GGTT GTTT TTTT TTTT TTTA TTAA TAAA AAAA AAAG AAGA AGAG GAGA AGAA GAAT AATT ATTA TTAA TAAG AAGT AGTA GTAA TAAT AATA ATAG TAGC AGCT GCTA CTAA TAAA AAAT AATA ATAA TAAT AATG ATGA TGAC GACT ACTT CTTT TTTT TTTT TTTG TTGA TGAT GATT ATTG TTGA TGAA GAAA AAAG AAGG AGGA GGAT GATT ATTA TTAT TATT ATTG TTGT TGTT\n",
            "AACT ACTA CTAG TAGG AGGG GGGA GGAA GAAA AAAA AAAA AAAT AATT ATTT TTTG TTGA TGAG GAGT AGTT GTTC TTCA TCAC CACT ACTC CTCC TCCT CCTC CTCA TCAA CAAG AAGA AGAA GAAG AAGC AGCT GCTG CTGA TGAG GAGG AGGA GGAA GAAA AAAA AAAG AAGA AGAT GATT ATTA TTAA TAAA AAAG AAGA AGAA GAAG AAGT AGTA GTAA TAAA AAAG AAGA AGAG GAGA AGAG GAGA AGAA GAAG AAGT AGTT GTTT TTTC TTCA TCAG CAGA AGAG GAGC AGCC GCCC CCCC\tCCTG CTGC TGCA GCAG CAGA AGAA GAAA AAAT AATC ATCA TCAA CAAA AAAA AAAT AATA ATAG TAGG AGGT GGTA GTAA TAAC AACA ACAA CAAT AATA ATAG TAGC AGCT GCTT CTTA TTAC TACT ACTG CTGC TGCT GCTT CTTA TTAG TAGC AGCA GCAT CATA ATAT TATG ATGC TGCT GCTA CTAG TAGT AGTT GTTT TTTA TTAT TATT ATTT TTTT TTTA TTAG TAGA AGAA GAAA AAAA AAAA AAAG AAGG AGGA GGAC GACT ACTT CTTA TTAA TAAC AACC ACCT CCTT CTTT TTTT\n",
            "ACCT CCTT CTTT TTTA TTAC TACC ACCG CCGC CGCA GCAA CAAC AACT ACTC CTCA TCAA CAAG AAGA AGAA GAAG AAGT AGTT GTTG TTGA TGAG GAGG AGGG GGGT GGTC GTCA TCAA CAAT AATA ATAT TATA ATAT TATT ATTA TTAA TAAT AATC ATCA TCAA CAAA AAAC AACT ACTG CTGG TGGT GGTG GTGG TGGT GGTA GTAG TAGA AGAG GAGG AGGT GGTA GTAA TAAC AACT ACTA CTAT TATG ATGG TGGT GGTC GTCA TCAC CACG ACGT CGTG GTGT TGTG GTGG TGGA GGAT\tTTAT TATT ATTC TTCA TCAA CAAC AACA ACAG CAGA AGAA GAAG AAGA AGAT GATT ATTC TTCT TCTT CTTC TTCA TCAT CATA ATAT TATT ATTC TTCT TCTT CTTT TTTC TTCT TCTT CTTA TTAA TAAA AAAG AAGC AGCT GCTC CTCT TCTT CTTT TTTT TTTG TTGT TGTC GTCA TCAC CACT ACTC CTCT TCTC CTCC TCCA CCAT CATT ATTA TTAT TATC ATCT TCTT CTTT TTTT TTTG TTGG TGGG GGGT GGTC GTCA TCAG CAGT AGTT GTTA TTAA TAAC AACT ACTC CTCT TCTA\n",
            "AACA ACAG CAGA AGAA GAAA AAAC AACT ACTT CTTT TTTA TTAC TACT ACTT CTTT TTTC TTCT TCTG CTGT TGTT GTTT TTTC TTCC TCCC CCCC CCCC CCCA CCAA CAAA AAAT AATA ATAT TATG ATGA TGAA GAAT AATA ATAA TAAC AACC ACCG CCGA CGAT GATT ATTC TTCA TCAG CAGG AGGC GGCT GCTA CTAC TACA ACAG CAGA AGAA GAAC AACC ACCT CCTC CTCC TCCA CCAG CAGC AGCC GCCC CCCC CCCA CCAA CAAG AAGA AGAG GAGT AGTT GTTA TTAA TAAC AACA\tCACC ACCA CCAG CAGT AGTT GTTA TTAG TAGA AGAC GACA ACAA CAAG AAGG AGGA GGAG GAGT AGTA GTAC TACA ACAA CAAG AAGC AGCA GCAG CAGC AGCA GCAT CATC ATCT TCTT CTTC TTCT TCTG CTGC TGCT GCTG CTGC TGCT GCTT CTTC TTCT TCTT CTTC TTCT TCTA CTAG TAGC AGCG GCGG CGGA GGAA GAAA AAAT AATA ATAA TAAT AATA ATAA TAAT AATG ATGG TGGA GGAT GATC ATCT TCTC CTCA TCAA CAAG AAGG AGGG GGGA GGAC GACT ACTC CTCG TCGA\n",
            "AGGA GGAG GAGA AGAA GAAG AAGT AGTT GTTA TTAA TAAT AATC ATCC TCCT CCTT CTTC TTCT TCTC CTCT TCTT CTTA TTAA TAAA AAAT AATG ATGA TGAC GACT ACTT CTTT TTTG TTGC TGCG GCGC CGCA GCAT CATA ATAA TAAC AACT ACTA CTAC TACT ACTT CTTA TTAA TAAA AAAA AAAG AAGT AGTC GTCA TCAA CAAG AAGA AGAA GAAG AAGT AGTT GTTT TTTT TTTA TTAA TAAG AAGT AGTT GTTC TTCT TCTC CTCA TCAA CAAT AATC ATCT TCTT CTTT TTTT TTTT\tTTAA TAAA AAAA AAAA AAAA AAAA AAAG AAGC AGCA GCAC CACT ACTC CTCT TCTT CTTT TTTA TTAC TACT ACTG CTGC TGCA GCAG CAGT AGTA GTAG TAGT AGTA GTAG TAGG AGGG GGGA GGAC GACA ACAG CAGG AGGA GGAG GAGT AGTT GTTT TTTT TTTA TTAG TAGC AGCT GCTC CTCC TCCT CCTG CTGT TGTA GTAG TAGT AGTT GTTG TTGC TGCT GCTA CTAC TACT ACTT CTTC TTCT TCTC CTCC TCCT CCTA CTAT TATA ATAG TAGT AGTT GTTA TTAG TAGA AGAG GAGA\n",
            "CCAG CAGA AGAA GAAA AAAT AATT ATTA TTAG TAGA AGAA GAAG AAGT AGTA GTAG TAGA AGAT GATC ATCG TCGT CGTA GTAA TAAC AACA ACAA CAAA AAAC AACT ACTG CTGT TGTT GTTG TTGT TGTT GTTC TTCT TCTG CTGA TGAA GAAA AAAA AAAT AATA ATAG TAGG AGGT GGTA GTAA TAAG AAGA AGAA GAAT AATA ATAG TAGA AGAC GACA ACAT CATG ATGG TGGA GGAC GACC ACCT CCTA CTAT TATA ATAG TAGG AGGA GGAT GATC ATCT TCTA CTAT TATA ATAA TAAA\tCTCA TCAA CAAA AAAC AACT ACTA CTAT TATA ATAG TAGC AGCT GCTA CTAG TAGC AGCA GCAT CATA ATAG TAGG AGGA GGAA GAAG AAGG AGGT GGTA GTAC TACT ACTA CTAT TATG ATGG TGGT GGTA GTAA TAAA AAAG AAGC AGCT GCTA CTAT TATG ATGT TGTG GTGG TGGA GGAA GAAA AAAT AATT ATTT TTTT TTTC TTCG TCGC CGCT GCTC CTCT TCTA CTAT TATT ATTA TTAA TAAT AATT ATTC TTCT TCTT CTTT TTTT TTTC TTCT TCTT CTTA TTAT TATA ATAT TATC\n",
            "cat: write error: Broken pipe\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "!bert --train_dataset '/home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert_corpus.txt' \\\n",
        "    --vocab_path '/home/hoangqd/Data/test/output/bertbimetaout/vocab' \\\n",
        "    --output_path '/home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model' \\\n",
        "    --epochs 20 \\\n",
        "    --hidden 128 \\\n",
        "    --layers 4 \\\n",
        "    --attn_heads 4 \\\n",
        "    --seq_len 256 \\\n",
        "    --batch_size 16 \\\n",
        "    --lr 1e-4 \\\n",
        "    --log_freq 100"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Vocab /home/hoangqd/Data/test/output/bertbimetaout/vocab\n",
            "Vocab Size:  656\n",
            "Loading Train Dataset /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert_corpus.txt\n",
            "Loading Dataset: 400it [00:00, 213152.28it/s]\n",
            "Loading Test Dataset None\n",
            "Creating Dataloader\n",
            "Building BERT model\n",
            "Creating BERT Trainer\n",
            "Total Parameters: 962322\n",
            "Training Start\n",
            "{'epoch': 0, 'iter': 0, 'avg_loss': 7.96380615234375, 'avg_acc': 50.0, 'loss': 7.96380615234375}\n",
            "EP_train:0: 100%|| 25/25 [00:23<00:00,  1.07it/s]\n",
            "EP0_train, avg_loss= 8.09812650680542 total_acc= 49.25\n",
            "EP:0 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep0\n",
            "{'epoch': 1, 'iter': 0, 'avg_loss': 8.26927661895752, 'avg_acc': 25.0, 'loss': 8.26927661895752}\n",
            "EP_train:1: 100%|| 25/25 [00:29<00:00,  1.18s/it]\n",
            "EP1_train, avg_loss= 7.81920804977417 total_acc= 49.5\n",
            "EP:1 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep1\n",
            "{'epoch': 2, 'iter': 0, 'avg_loss': 7.7504496574401855, 'avg_acc': 50.0, 'loss': 7.7504496574401855}\n",
            "EP_train:2: 100%|| 25/25 [00:35<00:00,  1.43s/it]\n",
            "EP2_train, avg_loss= 7.626161403656006 total_acc= 49.75\n",
            "EP:2 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep2\n",
            "{'epoch': 3, 'iter': 0, 'avg_loss': 7.474794864654541, 'avg_acc': 68.75, 'loss': 7.474794864654541}\n",
            "EP_train:3: 100%|| 25/25 [00:27<00:00,  1.11s/it]\n",
            "EP3_train, avg_loss= 7.3986496734619145 total_acc= 51.5\n",
            "EP:3 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep3\n",
            "{'epoch': 4, 'iter': 0, 'avg_loss': 7.305069923400879, 'avg_acc': 50.0, 'loss': 7.305069923400879}\n",
            "EP_train:4: 100%|| 25/25 [00:28<00:00,  1.16s/it]\n",
            "EP4_train, avg_loss= 7.286276512145996 total_acc= 49.75\n",
            "EP:4 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep4\n",
            "{'epoch': 5, 'iter': 0, 'avg_loss': 7.105582237243652, 'avg_acc': 62.5, 'loss': 7.105582237243652}\n",
            "EP_train:5: 100%|| 25/25 [00:32<00:00,  1.28s/it]\n",
            "EP5_train, avg_loss= 7.127226161956787 total_acc= 50.25\n",
            "EP:5 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep5\n",
            "{'epoch': 6, 'iter': 0, 'avg_loss': 7.082058906555176, 'avg_acc': 43.75, 'loss': 7.082058906555176}\n",
            "EP_train:6: 100%|| 25/25 [00:35<00:00,  1.42s/it]\n",
            "EP6_train, avg_loss= 7.026673259735108 total_acc= 50.25\n",
            "EP:6 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep6\n",
            "{'epoch': 7, 'iter': 0, 'avg_loss': 6.809267997741699, 'avg_acc': 43.75, 'loss': 6.809267997741699}\n",
            "EP_train:7: 100%|| 25/25 [00:36<00:00,  1.47s/it]\n",
            "EP7_train, avg_loss= 6.907491149902344 total_acc= 51.0\n",
            "EP:7 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep7\n",
            "{'epoch': 8, 'iter': 0, 'avg_loss': 6.7512311935424805, 'avg_acc': 43.75, 'loss': 6.7512311935424805}\n",
            "EP_train:8: 100%|| 25/25 [00:35<00:00,  1.44s/it]\n",
            "EP8_train, avg_loss= 6.821358089447021 total_acc= 51.0\n",
            "EP:8 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep8\n",
            "{'epoch': 9, 'iter': 0, 'avg_loss': 6.937045097351074, 'avg_acc': 37.5, 'loss': 6.937045097351074}\n",
            "EP_train:9: 100%|| 25/25 [00:33<00:00,  1.36s/it]\n",
            "EP9_train, avg_loss= 6.748660659790039 total_acc= 52.25\n",
            "EP:9 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep9\n",
            "{'epoch': 10, 'iter': 0, 'avg_loss': 6.747358322143555, 'avg_acc': 68.75, 'loss': 6.747358322143555}\n",
            "EP_train:10: 100%|| 25/25 [00:51<00:00,  2.07s/it]\n",
            "EP10_train, avg_loss= 6.638961677551269 total_acc= 49.25\n",
            "EP:10 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep10\n",
            "{'epoch': 11, 'iter': 0, 'avg_loss': 6.613818168640137, 'avg_acc': 43.75, 'loss': 6.613818168640137}\n",
            "EP_train:11: 100%|| 25/25 [00:47<00:00,  1.90s/it]\n",
            "EP11_train, avg_loss= 6.544880142211914 total_acc= 49.0\n",
            "EP:11 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep11\n",
            "{'epoch': 12, 'iter': 0, 'avg_loss': 6.552872180938721, 'avg_acc': 62.5, 'loss': 6.552872180938721}\n",
            "EP_train:12: 100%|| 25/25 [00:32<00:00,  1.29s/it]\n",
            "EP12_train, avg_loss= 6.4478693771362305 total_acc= 49.5\n",
            "EP:12 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep12\n",
            "{'epoch': 13, 'iter': 0, 'avg_loss': 6.404757976531982, 'avg_acc': 43.75, 'loss': 6.404757976531982}\n",
            "EP_train:13: 100%|| 25/25 [00:35<00:00,  1.40s/it]\n",
            "EP13_train, avg_loss= 6.326714115142822 total_acc= 48.0\n",
            "EP:13 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep13\n",
            "{'epoch': 14, 'iter': 0, 'avg_loss': 6.241936206817627, 'avg_acc': 37.5, 'loss': 6.241936206817627}\n",
            "EP_train:14: 100%|| 25/25 [00:37<00:00,  1.52s/it]\n",
            "EP14_train, avg_loss= 6.18299446105957 total_acc= 47.0\n",
            "EP:14 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep14\n",
            "{'epoch': 15, 'iter': 0, 'avg_loss': 6.287203311920166, 'avg_acc': 43.75, 'loss': 6.287203311920166}\n",
            "EP_train:15: 100%|| 25/25 [00:48<00:00,  1.92s/it]\n",
            "EP15_train, avg_loss= 6.100402069091797 total_acc= 50.75\n",
            "EP:15 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep15\n",
            "{'epoch': 16, 'iter': 0, 'avg_loss': 6.129057884216309, 'avg_acc': 62.5, 'loss': 6.129057884216309}\n",
            "EP_train:16: 100%|| 25/25 [00:51<00:00,  2.05s/it]\n",
            "EP16_train, avg_loss= 6.007933101654053 total_acc= 46.75\n",
            "EP:16 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep16\n",
            "{'epoch': 17, 'iter': 0, 'avg_loss': 5.985397815704346, 'avg_acc': 43.75, 'loss': 5.985397815704346}\n",
            "EP_train:17: 100%|| 25/25 [01:04<00:00,  2.60s/it]\n",
            "EP17_train, avg_loss= 5.8934172248840335 total_acc= 52.25\n",
            "EP:17 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep17\n",
            "{'epoch': 18, 'iter': 0, 'avg_loss': 5.941784858703613, 'avg_acc': 43.75, 'loss': 5.941784858703613}\n",
            "EP_train:18: 100%|| 25/25 [00:54<00:00,  2.19s/it]\n",
            "EP18_train, avg_loss= 5.8496888160705565 total_acc= 50.25\n",
            "EP:18 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep18\n",
            "{'epoch': 19, 'iter': 0, 'avg_loss': 5.9472880363464355, 'avg_acc': 43.75, 'loss': 5.9472880363464355}\n",
            "EP_train:19: 100%|| 25/25 [00:32<00:00,  1.30s/it]\n",
            "EP19_train, avg_loss= 5.759908313751221 total_acc= 45.25\n",
            "EP:19 Model Saved on: /home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep19\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "t4 = time.time()\n",
        "print('Train bert  model ...')\n",
        "bert_model = torch.load('/home/hoangqd/Data/test/output/bertbimetaout/S1_test.bert.model.ep19')\n",
        "\n",
        "vocab = WordVocab.load_vocab('/home/hoangqd/Data/test/output/bertbimetaout/vocab')\n",
        "bert_dataset = BERTDataset_ForInference(bert_corpus_file, vocab, seq_len=256, on_memory=True)\n",
        "bert_data_loader = DataLoader(bert_dataset, batch_size=1, num_workers=1)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "bert_model = bert_model.to(device) # device=cuda --> infer faster\n",
        "bert_model = bert_model.eval()\n",
        "\n",
        "all_embedding = []\n",
        "for idx, seed in enumerate(seeds):\n",
        "    # each element of this list is a read embedding\n",
        "    seed_embedding = []\n",
        "    for read_idx in seed:\n",
        "        data = bert_dataset[read_idx]\n",
        "        data = {key: value for key, value in data.items()}\n",
        "\n",
        "        # 1. forward the next_sentence_prediction and masked_lm model\n",
        "        with torch.no_grad():\n",
        "            read_embedding = bert_model(torch.unsqueeze(data[\"bert_input\"], 0).to(device), torch.unsqueeze(data[\"segment_label\"], 0).to(device)) # (1x256x256) ~ (batch_size x seq_length x hidden_length)\n",
        "            read_embedding = read_embedding.detach().cpu().numpy()[0] # (256 x 256) ~ (seq_length x hidden_length)\n",
        "            seed_embedding.append(read_embedding)\n",
        "    \n",
        "    # Convert to numpy array, and get the average of read embedding\n",
        "    seed_embedding = np.array(seed_embedding) # (len(seeds), 256, 256)\n",
        "    # print(seed_embedding.shape)\n",
        "    seed_embedding = np.mean(seed_embedding, axis=0) # (256, 256)\n",
        "    # print(seed_embedding.shape)\n",
        "\n",
        "    # Continue to average across token: (256, 256) -> (256,)\n",
        "    seed_embedding = np.mean(seed_embedding, axis=0)\n",
        "    # print(seed_embedding.shape)\n",
        "    all_embedding.append(seed_embedding)\n",
        "    # break\n",
        "\n",
        "\n",
        "print(len(all_embedding))\n",
        "print('Train bert model time: ', (time.time() - t4))\n",
        "log.write('\\nCTrain bert model time: ' + str(time.time() - t4))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading Dataset: 400it [00:00, 135716.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train bert  model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396\n",
            "Train bert model time:  9.322391986846924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# Clustering groups\n",
        "t6 = time.time()\n",
        "print('Clustering ...')\n",
        "kmeans = KMeans(\n",
        "    init=\"random\",\n",
        "    n_clusters=n_clusters,\n",
        "    n_init=100,\n",
        "    max_iter=200,\n",
        "    random_state=20210905)\n",
        "kmeans.fit(X=all_embedding, y=labels)\n",
        "y_pred_kmeans = kmeans.predict(X=all_embedding)\n",
        "print('Clustering time: ', (time.time() - t6))\n",
        "log.write('\\nClustering time: ' + str(time.time() - t6))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clustering ...\n",
            "Clustering time:  0.5102109909057617\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# Map read to group and compute F-measure\n",
        "t7 = time.time()\n",
        "print('Compute F-measure ...')\n",
        "log.write('\\nCompute measures: ')\n",
        "groupPrec = group_precision_recall(labels, groups, n_clusters)[0]\n",
        "f1 = genome_acc(groups, y_pred_kmeans, labels, n_clusters)[2]\n",
        "print('Group precision: ', groupPrec)\n",
        "print('F1-score: ', f1)\n",
        "print('Total time: ', (time.time() - t0))\n",
        "log.write('\\nGroup precision: ' + str(groupPrec))\n",
        "log.write('\\nF1-score: ' + str(f1))\n",
        "log.write('\\nTotal time: ' + str(time.time() - t0))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compute F-measure ...\n",
            "Group precision:  1.0\n",
            "F1-score:  0.5255819477434679\n",
            "Total time:  702.6991295814514\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "_69CfdGH3Z3t"
      }
    }
  ]
}